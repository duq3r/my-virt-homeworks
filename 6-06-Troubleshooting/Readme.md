# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
  
  ## Ответ <br>

  1. Найду запрос
   ```js
   db.currentOp({ "active" : true, "secs_running" : { "$gt" : 180 }})
   ```
   Он должен вернуть что-то вроде этого:
   ```js
   {
       "inprog" : [
           {
               //...
               "opid" : 29833,
               "secs_running" : NumberLong(436)
               //...
           }
       ]
   }
   ```
1. [Завершу](https://docs.mongodb.com/manual/tutorial/terminate-running-operations/#killop) принудительно
   ```
   db.killOp(29833)
   ```
   
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

Сначала следует проверить корректность запроса на предмет создание лишней нагрузки на сервис. Для этого можно использовать метод .explain("executionStats").
В некоторых случаях можно попробовать ограничить время его выполнения в коде:
~~~
db.collection_name.find(<query_string>).maxTimeMS(<time_limit>)
~~~
Дальше уже следует смотреть в сторону оптимизации работы БД, в частности индексов.
Если и там все хорошо, то следует заняться масштабированием.
Возможно, стоит убедиться в правильности выбора СУБД.



## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

 ## Ответ 2 <br>

 Тут явно похоже на проблемы с перегрузкой сервера. В частности похоже на нехватку оперативной памяти на сервере после многократного увеличения реплик.

 По пути процесса Redis /proc/id
 Можно выполнить команду
 ~~~
 сat smaps | grep 'Swap:'
 ~~~
 посмотреть заполняемость свапа и увидеть, если он сильно используется, то надо решать вопрос с оперативкой.

<br>
Блокировки могут происходить из-за избыточного количества ключей истекающих в одну и туже секунду, которые могут привысить 25% при дефолтных 20, указанных в параметре <b>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP</b>, что приведёт к повторному циклу очистки.

<br>
Для диагностики блокировок можно включить функцию мониторинга блокировок.
~~~
CONFIG SET watchdog-period 500
~~~
После диагностики выключить 
~~~
CONFIG SET watchdog-period 0
~~~




 
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

 ## Ответ 3 <br>
 
Описание задачи намекает на причину: таблица разрослась, в таком случае запросы могут выполняться долго. В сообщении упоминается `SELECT`, возможно в таблице просто не хватает индексов. 

Чтобы найти такие запросы, можно попробовать включить [slow_query_log](https://dev.mysql.com/_doc_/refman/8.0/en/server-system-variables.html#sysvar_slow_query_log).

В документации MySQL ошибке посвящена [эта](https://dev.mysql.com/doc/refman/8.0/en/error-lost-connection.html) статья, в ней перечислены три возможные причины:
* Слишком объёмные запросы на миллионы строк, и рекомендуют увеличить параметр `net_read_timeout`
* Небольшое значение параметра `connect_timeout`, клиент не успевает установить соединение
* Размер сообщения/запроса превышает размер буфера, заданного в переменной ` max_allowed_packet` [на сервере](https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_max_allowed_packet) или опцией `--max_allowed_packet` [клиента](https://dev.mysql.com/doc/refman/8.0/en/packet-too-large.html) 

Ещё можно предположить, что проблема в неактивности клиента. Это строга из лога SQLAlchemy, на [StackOverflow](https://stackoverflow.com/questions/29755228/sqlalchemy-mysql-lost-connection-to-mysql-server-during-query) предложили уменьшить параметр `pool_recycle` в SQLAlchemy и увеличить `wait_timeout` в [настройках](https://dev.mysql.com/doc/refman/5.6/en/server-system-variables.html#sysvar_wait_timeout) сервера MySQL.

## Возможные пути решения. 
Поправить все перечисленные параметры:
* Увеличить на сервере MySQL `wait_timeout`, `max_allowed_packet`, `net_write_timeout` и `net_read_timeout`
* В SQLAlchemy уменьшить `pool_recycle`, сделать меньше `wait_timeout`

Если ошибка пропадёт, возвращать по одному в исходное состояние, так должно получиться локализовать проблему.

Возможно достаточно будет оптимизировать запросы. Их можно найти включив `slow_query_log` и [настроив](https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_long_query_time) параметр `long_query_time` на значение близкое к `net_write_timeout` и `net_read_timeout`. 

Если проблема происходит только на селектах, вероятно изменения таймаутов и оптимизации запросов будет достаточно. Если ещё на инсертах - возможно, наоборот, нужно удалить часть индексов. 

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

 ## Ответ 4<br>

 ### Как вы думаете, что происходит?

`postmaster invoked oom-killer` - Out-Of-Memory Killer
На сервере заканчивается оперативная память и Линукс вызывает команду для очистки памяти, чтобы система не отказала.
Тем самым убивает(завершает) часть процессов, чтобы уберечь ядро от паники. 


### Как бы вы решили данную проблему?

Разобрался бы, какой процесс пожирает память, попробовал бы потюнить приложение, если это не postgres. 
Если postgres, то попробовал бы оптимизировать его настройками work_mem(выделение памяти под запрос), Maintenance_work_mem и autovacuum_work_mem (параметры отвечающие за очисткой неактуальных данных).
<br>
На крайний случай:
Увеличил бы оперативку на ВМке или swap. 


---